{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "def load_data(train_dir):\n",
    "    \"keep path of files of training data\"\n",
    "    emails_path = [os.path.join(train_dir+ str(i),f) for i in range(1,10) for f in os.listdir(train_dir + str(i))] \n",
    "    emails = []\n",
    "    targets = []\n",
    "    i=0\n",
    "    for email_path in emails_path:\n",
    "        with open(email_path,encoding='utf-8') as f:\n",
    "            emails.append(f.readlines()[1:][1]) # we do not take the first line of each emails which is the subject\n",
    "            file_name = emails_path[i].split(\"\\\\\")[3]\n",
    "            if(file_name[0:5]==\"spmsg\"):\n",
    "                targets.append('spam')\n",
    "            else:\n",
    "                targets.append('ham')    \n",
    "        i+=1\n",
    "    return emails,targets\n",
    "\n",
    "def data_preprocessing(data):\n",
    "    for doc_id,text in enumerate(emails):\n",
    "        '''Tokenization with a regex'''\n",
    "        tokens1 = tokenizer.tokenize(text.lower())\n",
    "        '''remove numbers'''\n",
    "        tokens2 = [token for token in tokens1 if(re.sub('\\d+','', token)!='')]\n",
    "        '''Stopword removal'''\n",
    "        filtered = [w for w in tokens2 if not w in stopwords.words('english')]\n",
    "        '''Lemmatization'''\n",
    "        filtered_lemm = []\n",
    "        for w in filtered:\n",
    "            noun = lemmatizer.lemmatize(w, pos='n')\n",
    "            verb = lemmatizer.lemmatize(w, pos='v')\n",
    "            if(noun!=w):\n",
    "                filtered_lemm.append(noun)\n",
    "            else:\n",
    "                filtered_lemm.append(verb)\n",
    "        '''Covenrt list of words to one string'''\n",
    "        doc = ' '.join(w for w in filtered_lemm)\n",
    "        emails[doc_id] = doc  \n",
    "    return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_dir =\".\\\\bare\\\\part\"\n",
    "emails,targets = load_data(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+') #This tokenizer removes punctuation\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "train_data = data_preprocessing(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'date sun dec est michael mmorse vm1 yorku ca subject query wlodek zadrozny ask anything interest say construction np np second much relate might consider construction form discuss list late reduplication logical sense john mcnamara name tautologous thus level indistinguishable well well say john mcnamara name tautologous give support say logic base semantics irrelevant natural language sense tautologous supply value attribute follow attribute value fact value name attribute relevant entity chaim shmendrik john mcnamara name would false tautology reduplication either'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
